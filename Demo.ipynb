{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Demo.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"sDAqDHbz-XrK","colab_type":"code","outputId":"ffc499f2-a7b0-417d-c4dc-0d8d666febbc","executionInfo":{"status":"ok","timestamp":1587794957529,"user_tz":-330,"elapsed":3962,"user":{"displayName":"Sourabh Prakash","photoUrl":"","userId":"07057922078086223192"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Byp5MLC3_IGu","colab_type":"code","colab":{}},"source":["import os\n","os.chdir(\"drive/My Drive/college_project/ACDC/estimators\")\n","#os.listdir()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLwoCIp7gE43","colab_type":"code","colab":{}},"source":["import argparse\n","import os, sys, shutil\n","import numpy as np \n","import time\n","from estimator import *\n","from config import *\n","sys.path.insert(0,'../models/')\n","from network import *\n","from network_ops import *\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l5gvbett7FAL","colab_type":"code","colab":{}},"source":["import matplotlib\n","matplotlib.use('TKAgg')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"98CzuHT-7mE_","colab_type":"code","outputId":"1018257f-1627-4300-d44b-0704a8522201","executionInfo":{"status":"ok","timestamp":1587794992404,"user_tz":-330,"elapsed":6506,"user":{"displayName":"Sourabh Prakash","photoUrl":"","userId":"07057922078086223192"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["pip install SimpleITK"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: SimpleITK in /usr/local/lib/python3.6/dist-packages (1.2.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qb9kwL767x2S","colab_type":"code","outputId":"a7b14061-7ca6-416c-cd8a-129a941ff941","executionInfo":{"status":"ok","timestamp":1587794718314,"user_tz":-330,"elapsed":47618,"user":{"displayName":"Sourabh Prakash","photoUrl":"","userId":"07057922078086223192"}},"colab":{"base_uri":"https://localhost:8080/","height":634}},"source":["!pip install tensorflow==1.12.0"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.12.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n","\u001b[K     |████████████████████████████████| 83.1MB 61kB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.12.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.3.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.34.2)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.8.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.18.3)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (3.10.0)\n","Collecting tensorboard<1.13.0,>=1.12.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 57.0MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.9.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.0.8)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.28.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12.0) (46.1.3)\n","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.2.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12.0) (2.10.0)\n","Installing collected packages: tensorboard, tensorflow\n","  Found existing installation: tensorboard 2.2.1\n","    Uninstalling tensorboard-2.2.1:\n","      Successfully uninstalled tensorboard-2.2.1\n","  Found existing installation: tensorflow 2.2.0rc3\n","    Uninstalling tensorflow-2.2.0rc3:\n","      Successfully uninstalled tensorflow-2.2.0rc3\n","Successfully installed tensorboard-1.12.2 tensorflow-1.12.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tensorboard","tensorflow"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"HKqWfKsIi127","colab_type":"code","outputId":"dd87739e-8271-4ce4-802b-702bdf4eb1fe","executionInfo":{"status":"error","timestamp":1587795018826,"user_tz":-330,"elapsed":14439,"user":{"displayName":"Sourabh Prakash","photoUrl":"","userId":"07057922078086223192"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","\n","if __name__ == '__main__':\n","    conf = conf()\n","    inputs = tf.placeholder(tf.float32, shape=(None, None, None, conf.num_channels))\n","    targets = tf.placeholder(tf.uint8, shape = (None, None, None))\n","    weight_maps = tf.placeholder(tf.float32, shape=[None, None, None])\n","    batch_class_weights = tf.placeholder(tf.float32)\n","\n","    # define the net\n","    print('Defining the network', conf.run_name)\n","    # model = FCMultiScaleResidualDenseNet(inputs,\n","    #                         targets, \n","    #                         weight_maps,\n","    #                         batch_class_weights,\n","    #                         num_class=conf.num_class,\n","    #                         n_pool = 3, \n","    #                         n_feat_first_layer = [12, 12, 12], \n","    #                         growth_rate = 12,\n","    #                         n_layers_per_block = [2, 3, 4, 5, 4, 3, 2], \n","    #                         weight_decay = 5e-6, \n","    #                         dropout_rate = 0.2, \n","    #                         optimizer = AdamOptimizer(conf.learning_rate),\n","    #                         metrics_list = ['sW_CE_loss', 'mBW_Dice_loss', 'L2_loss', 'Total_loss', 'avgDice_score',\n","    #                                         'Dice_class_1', 'Dice_class_2', 'Dice_class_3'],\n","    #                         metrics_to_optimize_on = ['Total_loss']\n","    #                       )\n","\n","    model = FCMultiScaleResidualDenseNet(inputs,\n","                            targets, \n","                            weight_maps,\n","                            batch_class_weights,\n","                            num_class=conf.num_class,\n","                            n_pool = 3, \n","                            n_feat_first_layer = [16, 16, 16], \n","                            growth_rate = 16,\n","                            n_layers_per_block = [2, 3, 4, 5, 4, 3, 2], \n","                            weight_decay = 5e-6, \n","                            dropout_rate = 0.2, \n","                            optimizer = AdamOptimizer(conf.learning_rate),\n","                            metrics_list = ['sW_CE_loss', 'mBW_Dice_loss', 'L2_loss', 'Total_loss', 'avgDice_score',\n","                                            'Dice_class_1', 'Dice_class_2', 'Dice_class_3'],\n","                            metrics_to_optimize_on = ['Total_loss']\n","                          )\n","\n","    # initialise the estimator with the net\n","    print('Preparing the estimator..')\n","    trainer = Estimator(model = model,\n","                        conf = conf\n","                        )\n","    # iterate for the number of epochs\n","    for epoch in range(int(trainer.numKeeper.counts['epoch']+1), conf.num_epochs):\n","        print('\\n\\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$')\n","        print('Training @ Epoch : ' + str(epoch))\n","        trainer.Fit(steps=-1)\n","        print('\\n---------------------------------------------------')\n","        print('Validating @ Epoch : ' + str(epoch))\n","        trainer.Evaluate(steps=-1 )\n","        trainer.numKeeper.counts['epoch'] = trainer.numKeeper.counts['epoch'] + 1\n","        trainer.numKeeper.UpdateCounts(trainer.summary_manager.counts)\n","        trainer.SaveModel(os.path.join(conf.output_dir,conf.run_name,'models','latest.ckpt'))\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Defining the network FCRD_ACDC\n","First Layer shape  [None, None, None, 48]\n","DB_Down: 0  shape  [None, None, None, 80]\n","DB Projection Layer:  shape  [None, None, None, 48]\n","TD: 0  shape  [None, None, None, 80]\n","DB_Down: 1  shape  [None, None, None, 128]\n","DB Projection Layer:  shape  [None, None, None, 64]\n","TD: 1  shape  [None, None, None, 128]\n","DB_Down: 2  shape  [None, None, None, 192]\n","DB Projection Layer:  shape  [None, None, None, 80]\n","TD: 2  shape  [None, None, None, 192]\n","Bottleneck Projection Layer:  shape  [None, None, None, 80]\n","Bottleneck:  shape  [None, None, None, 80]\n","TU: 0  shape  [None, None, None, 80]\n","Transition Up Projection Layer:  shape  [None, None, None, 64]\n","DB_Up: 0  shape  [None, None, None, 64]\n","TU: 1  shape  [None, None, None, 64]\n","Transition Up Projection Layer:  shape  [None, None, None, 48]\n","DB_Up: 1  shape  [None, None, None, 48]\n","TU: 2  shape  [None, None, None, 48]\n","Transition Up Projection Layer:  shape  [None, None, None, 32]\n","DB_Up: 2  shape  [None, None, None, 32]\n","Final Stack: 2  shape  [None, None, None, 80]\n","Final Softmax Layer:  shape  [None, None, None, 4]\n","Predictions:  shape  [None, None, None]\n","WARNING:tensorflow:From ../models/network_ops.py:57: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","Total Number of Trainable Parameters: 651316\n","Preparing the estimator..\n","Initializing iterators for dataloaders\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-1b4fd615c09b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Preparing the estimator..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     trainer = Estimator(model = model,\n\u001b[0;32m---> 49\u001b[0;31m                         \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                         )\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# iterate for the number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/college_project/ACDC/estimators/estimator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, conf)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Initializing iterators for dataloaders'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         self.train_iterator = DataIterator(conf.data_path, conf.transformation_params, \n\u001b[0;32m---> 24\u001b[0;31m                                 mode = 'train', batch_size = conf.batch_size, num_threads=4)\n\u001b[0m\u001b[1;32m     25\u001b[0m         self.valid_iterator = DataIterator(conf.data_path, conf.transformation_params,\n\u001b[1;32m     26\u001b[0m                                 mode = 'valid', batch_size = conf.batch_size, num_threads=4)\n","\u001b[0;32m/content/drive/My Drive/college_project/ACDC/data_loaders/hdf5_loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_path, transformation_params, mode, batch_size, num_threads, max_imgs_in_ram)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone_event\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_over_for_thread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetFilePaths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformation_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformation_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/college_project/ACDC/data_loaders/hdf5_loader.py\u001b[0m in \u001b[0;36mGetFilePaths\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             train_files = [os.path.join(self.data_path,'train_set',f) \n\u001b[0;32m---> 54\u001b[0;31m                         for f in os.listdir(os.path.join(self.data_path,'train_set'))]\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../processed_acdc_dataset/hdf5_files/train_set'"]}]},{"cell_type":"code","metadata":{"id":"ax0ITun7xxlz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}